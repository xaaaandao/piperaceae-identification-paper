{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "extractor = {\n",
    "    \"lbp\": [59],\n",
    "    \"surf64\": [128, 256, 257],\n",
    "    \"surf128\": [128, 256, 513],\n",
    "    \"mobilenetv2\": [128, 256, 512, 1024, 1280],\n",
    "    \"resnet50v2\": [128, 256, 512, 1024, 2048],\n",
    "    \"vgg16\": [128, 256, 512]\n",
    "}\n",
    "\n",
    "list_classifiers = [\"DecisionTreeClassifier\", \"KNeighborsClassifier\", \"MLPClassifier\", \"RandomForestClassifier\", \"SVC\"]\n",
    "list_dimensions = [256, 400, 512]\n",
    "list_patch = [\"patch=3\", \"patch=5\", \"patch=7\"]\n",
    "list_orientation_patch = [\"horizontal\", \"vertical\"]\n",
    "list_type_mask = [\"_manual_\", \"_unet_\"]\n",
    "list_info = [\"_mean_\", \"_std_\"]\n",
    "list_dataset = [\"unet\", \"iwssip\", \"matlab\", \"photoshop\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "index = [k + s + str(d) for s in list_info for k, v in extractor.items() for d in v]\n",
    "index_time = [k + \"_\" + str(d) for k, v in extractor.items() for d in v]\n",
    "csv_per_dataset = {d: {\"sheet_mean\": {\"columns\": [c + \"_iwssip_\" + str(d) for c in list_classifiers for d in list_dimensions], \"index\": index}, \"sheet_time\": {\"columns\": [c + \"_iwssip_\" + str(d) for c in list_classifiers for d in list_dimensions], \"index\": index_time}} for p in list_patch for o in list_orientation_patch for d in list_dataset if d.lower() != \"iwssip\"}\n",
    "\n",
    "for s in csv_per_dataset.keys():\n",
    "    for c in list_classifiers:\n",
    "        for d in list_dimensions:\n",
    "            csv_per_dataset[s][\"sheet_mean\"][\"columns\"].append(c + \"_\" + s + \"_\" + str(d))\n",
    "\n",
    "for p in csv_per_dataset.keys():\n",
    "    csv_per_dataset[p][\"sheet_mean\"] = pandas.DataFrame(columns=sorted(csv_per_dataset[p][\"sheet_mean\"][\"columns\"]), index=sorted(csv_per_dataset[p][\"sheet_mean\"][\"index\"]))\n",
    "    csv_per_dataset[p][\"sheet_time\"] = pandas.DataFrame(columns=sorted(csv_per_dataset[p][\"sheet_time\"][\"columns\"]), index=sorted(csv_per_dataset[p][\"sheet_time\"][\"index\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "list_files = list([file for file in pathlib.Path(\"./r/GRAYSCALE\").rglob(\"mean.csv\") if file.is_file()])\n",
    "\n",
    "patch = \"patch=3\"\n",
    "orientation = \"horizontal\"\n",
    "dataset = \"lbp\"\n",
    "\n",
    "for file in list_files:\n",
    "    data = pandas.read_csv(file, sep=\";\", header=None, index_col=0).squeeze()\n",
    "\n",
    "    get_dataset = list(filter(lambda x: x.lower() in str(file).lower(), list_dataset))[0]\n",
    "    get_dim = list(filter(lambda x: str(x).lower() in str(file).lower(), list_dimensions))[0]\n",
    "    filename = str(file).replace(str(get_dim), \"\", 1)\n",
    "    get_extractor = list(filter(lambda x: x.lower() in str(filename).lower(), list(extractor.keys())))[0]\n",
    "    get_classifier = list(filter(lambda x: x.lower() in str(filename).lower(), list_classifiers))[0]\n",
    "    get_patch = list(filter(lambda x: x.lower() in str(filename).lower(), list_patch))\n",
    "    get_patch = \"patch=0\" if len(get_patch) == 0 else get_patch[0]\n",
    "    get_orientation_patch = list(filter(lambda x: x.lower() in str(filename).lower(), list_orientation_patch))\n",
    "    get_orientation_patch = \"inteiro\" if len(get_orientation_patch) == 0 else get_orientation_patch[0]\n",
    "\n",
    "    get_features = list(filter(lambda x: str(x) in str(filename), extractor[get_extractor]))\n",
    "    for f in get_features:\n",
    "\n",
    "        # print(get_dataset, f, get_dim, get_extractor, get_classifier)\n",
    "        # print(file)\n",
    "\n",
    "        if get_patch == patch and get_orientation_patch == orientation and get_dataset == dataset:\n",
    "            if get_dataset==\"iwssip\":\n",
    "                for c in csv_per_dataset.keys():\n",
    "                    index_df = get_extractor + \"_mean_\" + str(f)\n",
    "                    column_df = get_classifier + \"_\" +  get_dataset + \"_\" + str(get_dim)\n",
    "                    csv_per_dataset[c][\"sheet_mean\"].loc[index_df, column_df] = float(data[\"mean_sum\"])\n",
    "\n",
    "                    index_df = get_extractor + \"_std_\" + str(f)\n",
    "                    print(f\"aa{index_df, column_df}\")\n",
    "                    csv_per_dataset[c][\"sheet_mean\"].loc[index_df, column_df] = \"±\" + data[\"std_sum\"]\n",
    "\n",
    "                    index_df_time = get_extractor + \"_\" + str(f)\n",
    "                    csv_per_dataset[c][\"sheet_time\"].loc[index_df_time, column_df] = data[\"mean_time_millisec\"]\n",
    "\n",
    "            else:\n",
    "                index_df = get_extractor + \"_mean_\" + str(f)\n",
    "                column_df = get_classifier + \"_\" +  get_dataset + \"_\" + str(get_dim)\n",
    "                # print(index_df, column_df)\n",
    "                csv_per_dataset[get_dataset][\"sheet_mean\"].loc[index_df, column_df] = float(data[\"mean_sum\"])\n",
    "\n",
    "                index_df = get_extractor + \"_std_\" + str(f)\n",
    "                print(f\"bb{index_df, column_df}\")\n",
    "                csv_per_dataset[get_dataset][\"sheet_mean\"].loc[index_df, column_df] = \"±\" + data[\"std_sum\"]\n",
    "\n",
    "                index_df_time =  get_extractor + \"_\" + str(f)\n",
    "                csv_per_dataset[get_dataset][\"sheet_time\"].loc[index_df_time, column_df] = data[\"mean_time_millisec\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "for p in csv_per_dataset.keys():\n",
    "    csv_per_dataset[p][\"sheet_mean\"].to_csv(f\"main_mean_{p}.csv\", decimal=\",\", sep=\";\", quoting=csv.QUOTE_ALL, mode=\"w\")\n",
    "    csv_per_dataset[p][\"sheet_time\"].to_csv(f\"main_time_{p}.csv\", decimal=\",\", sep=\";\", quoting=csv.QUOTE_ALL, mode=\"w\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
